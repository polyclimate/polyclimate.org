[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "A place to think about collaborative climate science."
  },
  {
    "objectID": "posts/new-scenarios/index.html",
    "href": "posts/new-scenarios/index.html",
    "title": "New Scenarios",
    "section": "",
    "text": "(a) Figure 1 from Vuuren et al. (2023) (CC-BY)\n\n\n\n\n\n\n\n(b) Figure 2a from Meinshausen et al. (2023) (CC-BY)\n\n\n\n\nFigure 1: Illustrative emission pathway sketches in Vuuren et al. (2023) and Meinshausen et al. (2023)\nLast week a new paper and a new preprint on scenario creation and their assessment were published. First, a group effort with 41 co-authors: A perspective on the next generation of Earth system model scenarios: towards representative emission pathways (REPs) (Meinshausen et al. 2023). It’s open for review comments in GMD. The social media comments I saw so far where quite mixed. Some were apparently seeing this as a community split and invited to join the ScenarioMIP process, while the paper itself presents itself as a contribution to the ScenarioMIP effort.\n(p. 25)\n(p. 31/32)\nGiven that I started Polyclimate as a place to think about how (some parts of) climate science could be done more in the open and collaboratively I find these discussions quite fascinating and look forward to a future study which analyses the social and political processes behind the scenario development.\nPierre Friedlingstein on Twitter\nIt’s often hard to get review comments1, but the naming of their proposed scenarios is definitely something that will lead to comments. Whether there are emissions pathways that can be ruled out is still up for debate.\nGenevieve Guenther on Twitter\nOthers were excited about both the “hypothetical” loss and damage scenario with emisssions reductions having started in 2015 and the high emissions scenarios.\nKetan Joshi on Bluesky\nThere is a a lot of literature which tries to assign historical emissions responsibility and the loss and damage debate will certainly be important in the next climate negotiations.\nWillem Huiskamp on Bluesky\nAn important question then is of course how such a hypothetical scenario would look. 5% emissions reductions from 2015? 10%?\nAlso interesting to note that a sketch in in the ScenarioMIP workshop report (Vuuren et al. 2023) has a question mark pathway in the area between ‘continued’ emissions and a below-2°C pathway, an area which is left empty in the REP sketch, see Figure 1. The selection, design and naming of scenarios has many implications and there is not much time if things are to be ready for the second Global Stocktake in 2028.\nGiven the discussions on timelines and cut-off dates Figure 2 for scenarios and their assessment feeding into the second Global Stocktake via a yet unknown AR7 product another paper published last week is also quite relevant: AR6 scenarios database: an assessment of current practices and future recommendations (Peters et al. 2023).\nA critical assessment of the mitigation scenarios assessed in WG3 of the IPCC it calls for a “A new generation mitigation scenarios database” and for having the scenarios assessment be public during the assessment process instead of only after the final report publication.\nFrom a description of the current process, an analysis of skewness in the distribution of submitted scenarios (dominated by a small number of models and projects, see Figure 3) it makes several proposals. Quoting from a thread on Twitter2:\n(Glen Peters on Twitter)\nFor the proposal of a living scenario database I believe the ingredients are already there. With the fantastic climate-assessment package Kikstra et al. (2022) have open-sourced the core climate assessment engine. A future living scenario database could built on this and be developed in the open on GitHub, along future improvements and updates to the assessment pipeline. With a total size of less than 350 MB for the global scenarios3 the database could fit well below into the recommended limits of a GitHub repository of 1GB so there might be no need to maintain an actual database. If needed it could also be split up into sub-projects.\nSeveral approaches could be possible, for example submitting scenarios via Pull Requests to a central scenario DB repository, the assessment being handled by an automated pipeline using GitHub Actions writing back the results to the repository. A distributed, local approach might be another possibility, if the computing demands are to high to be handled by (free tier) GitHub Actions.\nScenario developers would then have to run the pipeline locally and submit not only their input data but also the harmonized emissions and climate assessment to a central repository database. This approach might even be better for scenario developers (or done locally before submission anyways) and avoid surprises like re-classification due to infilling and harmonization. For example, they might have thought they submitted a below 1.5 scenario, but filling in emissions not covered in their model could push it into an overshoot one. During submission via Pull Requests automated checks could be performed like they are done in the current submission portal. Ideally, the submitted scenarios would directly be rendered into visualizations and be explorable on a website. Archiving could happen through the Zenodo integration with GitHub, so there would always be a citable reference of the latest version.\nLots of possibilities and not much time. Leave your thoughts and comments below!"
  },
  {
    "objectID": "posts/new-scenarios/index.html#footnotes",
    "href": "posts/new-scenarios/index.html#footnotes",
    "title": "New Scenarios",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLeave your thoughts and comments below!↩︎\nIf the URL still says Twitter, I can still call the network Twitter, right?↩︎\nAR6_Scenarios_Database_World_v1.1.csv and AR6_Scenarios_Database_metadata_indicators_v1.1.xlsx↩︎"
  },
  {
    "objectID": "posts/announcing-project-polyclimate/index.html",
    "href": "posts/announcing-project-polyclimate/index.html",
    "title": "Announcing Project Polyclimate",
    "section": "",
    "text": "It is 100 days until COP28 in Dubai. The Global Stocktake, the process to assess progress towards the goals of the Paris Climate Change Agreement, is scheduled to take place every five years and for the first time during COP28.\nSome questions and indicators one might ask about during such a Global Stocktake, or in fact constantly, when thinking about climate change, could be:\n\nWhat are global emissions levels?\nHow far are we from 1.5 or 2.0°C?\nHow big is the remaining carbon budget?\nWhen adding together climate plans of countries (NDCs), where do we end up?\n\nWhen trying to look up an answer for questions like these, they can be surprisingly difficult to find given their importance for our common future. Of course answers exist, in academic publications, in reports like those from the IPCC, or in reports or websites from various governmental or non-governmental organizations. Few of them however are regularly updated and fully done reproducibly in the spirit of open science, where the latter would make it easier to achieve the former.\n\nPolyclimate\nThe Polyclimate project is a place to think about how questions like the above could be approached using modern tools for collaboration, to discuss what are the barriers that so far prevented such collaboration from happening, and to hopefully kickstart some actual work on producing answers to these questions in a regularly updated, open, and inclusive way.\nIt is of course named after and inspired by the Polymath project. In 2009 Timothy Gowers asked in his blog the question:\n\n“Is massively collaborative mathematics possible?”.\n\nThe answer is of course yes, numerous publications and succesful proofs have emerged from the project and follow-ups. In the post he writes\n\n“I’ve been thinking of doing this for a long time.”\n\nSo have I on doing this for some questions of climate science and when looking up whether someone had already used “Polyclimate” for this I was happily surprised to find some discussion in this blog. This went apparently nowhere, and, to be clear, I am not interested in using “collective intelligence” or the “power of the internet” to “move forward on the climate debate”. Nonetheless, there are some interesting observations made, for example Michael Nielsen commented on the idea of mass collaboration:\n\nA crucial question about mass collaboration is when problems can be attacked using mass collaboration, and when it will fail. I believe the key question is whether the community involved in the collaboration has a “shared praxis” or not. By this, I mean a powerful set of shared techniques and agreed-upon methods of reasoning which all participants agree to use.\n[…]\nFor climate change the issue of a shared praxis seems complicated. I think it’s pretty near a dividing line. Reading online discussions of climate, it’s obvious that many people don’t even share the same basic modes of reasoning: what one person counts as “evidence” is ignored by others, basic standards of logic are outright ignored, and so on.\n\nI don’t think massive online collaboration is needed, but getting a number of researchers working together, which is larger than the usual teams collaborating on questions like the ones mentioned above could have tremendous benefits. There are many areas where finding the right specialist, for example with knowledge of some specific sector’s emission could be enabled by the internet much more likely than in traditional academic collaboration.\nSo this Polyclimate project is not about solving the “climate issue”. It is also not about the climate in urban systems which I discovered when searching for “polyclimate”:\n\nFar more attached to the subject than Friedman, Schulze-Fielitz spent 20 years studying the air-conditioning of “urban systems.” His concept of “Polyclimate” went hand in hand with Raumstadt: to each activity its space and its climate. (Rouillard 2018)\n\nI hope Polyclimate can move forward the way in which researchers work together on some of the grunt work, producing basic data sets and indicators which are crucial for all of climate science but due to various reasons are not done continuously in a fully open, collaborative manner. Certainly, one can learn from the successes in online collaboration in Mathematics.\n\n\nPolymath\nAn article in Nature (unfortunately paywalled, but available online at the author’s website) summarizes the Polymath story and lines out ideas for other disciplines:\n\nThe ‘Polymath Project’ proved that many minds can work together to solve difficult mathematical problems. (Gowers and Nielsen 2009)\n\nBuilding up a regularly updated global emissions or temperature dataset is of course quite different from finding a new proof, but there are many insights which can be adapted from the experiences of the Polymath projects.\nIn his book Reinventing Discovery Michael Nielsen argues that scientists are more likely to contribute to projects like Polymath or Galaxy Zoo where the final output is a classical output like a scientific paper compared to projects like GenBank or Wikipedia, where their expertise would be helpful as well but is not as incentivized (p.9, Nielsen 2011). In Polymath, papers were published under the pseudonym D. H. J. Polymath. I believe that publishing under pseudonym or as a working group is a critical component in getting collaborative and repeatedly updated climate science to work.\nThere are many challenges for any such project and it is quite interesting to go back through the archives of Timothy Gower’s blog for the Polymath category, read about the process, and find for example discussions on thread depth for the blog:\n\nOn the Polymath blog, a very high level of threading is allowed, with the result that the order of comments is very different from their chronological order. This makes it substantially harder to check what has been added recently than it would be if there were no threading. It’s not impossible, since one has a list of recent comments, but it does reduce the feeling of a polymathematical thought process unfolding over time. I know that there is disagreement about this, but I am going back to the view that there should be no threading at all, though I might be ready to compromise and have threading down to depth 1, with the understanding that it should be used for brief local replies only.\n\n\n\nWhere to start?\nPolymath started and happened to a large part on blogs. Looking for a place where I could start thinking about these questions I settled on GitHub and set up the blog you are reading now using Quarto. The latter enables inclusion of mathematical citation, code execution and citations. Comments are enabled in the blog using GitHub’s discussion feature through Giscus. Next to code hosting GitHub also offers Wikis, project management, issue tracking, and automated code pipelines, which means pretty much all potential ingredients for such collaborative work are there. Further, quite a few of the people I could imagine contributing to such efforts are already actively doing science in the open on GitHub, so if you have an account there you are ready to comment and contribute.\nFor any work done in public there are concerns about trolls, here GitHub has features for limiting interaction. As on most social platforms there can be difficulties for people from countries under trade control regulations, but for the usage of the free GitHub tools there should be no impediment in contributing. GitHub is a social platform, so it might be possible to recreate some of the fruitful collaboration which used to happen on sites like Twitter, where tagging the user account of a person knowledgeable on a niche topic could get them into a conversation and generate new insights.\nWith Manubot there is also a successful usage of GitHub as platform for collaborative science, developed during writing the Deep Review, a review article on deep learning in precision medicine (Ching et al. 2018; Himmelstein et al. 2019).\nChallenges in online collaboration are of course partly technical, but I believe mostly social. Working in the open has benefits, but can also create new opportunities.\nOn the challenges with the research questions stated above, is it lack of funding for updates, which are just updates and not novel, shiny discoveries? Does the current academic system with its many short-term contracts disincentivize such work?\nWhat questions in general could or should be approached in such a collaborative manner?\nLeave your thoughts and ideas in the comments. (Sign up on GitHub if you haven’t already.)\n\n\n\n\n\nReferences\n\nChing, Travers, Daniel S. Himmelstein, Brett K. Beaulieu-Jones, Alexandr A. Kalinin, Brian T. Do, Gregory P. Way, Enrico Ferrero, et al. 2018. “Opportunities and Obstacles for Deep Learning in Biology and Medicine.” Journal of The Royal Society Interface 15 (141): 20170387. https://doi.org/10.1098/rsif.2017.0387.\n\n\nGowers, Timothy, and Michael Nielsen. 2009. “Massively Collaborative Mathematics.” Nature 461 (7266): 879–81. https://doi.org/10.1038/461879a.\n\n\nHimmelstein, Daniel S., Vincent Rubinetti, David R. Slochower, Dongbo Hu, Venkat S. Malladi, Casey S. Greene, and Anthony Gitter. 2019. “Open Collaborative Writing with Manubot.” Edited by Dina Schneidman-Duhovny. PLOS Computational Biology 15 (6): e1007128. https://doi.org/10.1371/journal.pcbi.1007128.\n\n\nNielsen, Michael. 2011. Reinventing Discovery: The New Era of Networked Science. Princeton University Press.\n\n\nRouillard, Dominique. 2018. “Megaspace Structure Yona Friedman and Eckhard Schulze–Fielitz.” Histories of Postwar Architecture, no. 3: 3–18."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Polyclimate",
    "section": "",
    "text": "New Scenarios\n\n\n\n\n\n\n\nPolyclimate\n\n\nScenarios\n\n\n\n\nCreation and Assessment of Climate Scenarios.\n\n\n\n\n\n\nSep 12, 2023\n\n\nRobert Gieseke\n\n\n\n\n\n\n  \n\n\n\n\nPolyclimate Global Projections\n\n\n\n\n\n\n\nPolyclimate\n\n\nPolyclimate1\n\n\nGlobal Projections\n\n\n\n\nCarbon Budgets, Temperature Pathways and a proposal for Global Projections based on stylized scenarios.\n\n\n\n\n\n\nSep 4, 2023\n\n\nRobert Gieseke\n\n\n\n\n\n\n  \n\n\n\n\nPolyclimate Emissions\n\n\n\n\n\n\n\nPolyclimate\n\n\nEmissions\n\n\n\n\nThoughts on a Polyclimate Emissions project.\n\n\n\n\n\n\nAug 24, 2023\n\n\nRobert Gieseke\n\n\n\n\n\n\n  \n\n\n\n\nAnnouncing Project Polyclimate\n\n\n\n\n\n\n\nPolyclimate\n\n\nPolymath\n\n\n\n\nA place to think about collaborative climate science.\n\n\n\n\n\n\nAug 22, 2023\n\n\nRobert Gieseke\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/polyclimate-emissions/index.html",
    "href": "posts/polyclimate-emissions/index.html",
    "title": "Polyclimate Emissions",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nplt.style.use(\"ggplot\")\n\ncat_df = pd.read_excel(\n    \"https://climateactiontracker.org/documents/1131/CAT_2022_Warming_projections_global_update.xlsx\", \n    sheet_name=\"Global Emissions time series\"\n)\n\ncat = pd.DataFrame(cat_df.iloc[23, 3:].values, index=cat_df.iloc[13, 3:].astype(int)).dropna()\ncat.columns = [\"CAT\"]\n\nipcc = pd.read_excel(\n    \"https://open-data.metadata.works/ipcc/437/ipcc_ar6_figure_spm_1_archive.xlsx?response-content-disposition=attachment\",\n    sheet_name=\"panel_a\"\n)\nipcc = ipcc.groupby(\"year (panel_a)\").sum()\nipcc.index.name = \"year\"\nipcc = ipcc.iloc[:, -1]\n\nigcc = pd.read_csv(\"https://github.com/ClimateIndicator/GHG-Emissions-Assessment/raw/main/results/ghg_emissions_co2e.csv\", index_col=0)\n\nfig, ax = plt.subplots()\nipcc.plot(ax=ax)\nigcc.loc[1990:, :].iloc[:, 1:].sum(axis=1).plot(ax=ax)\ncat.plot(ax=ax, legend=False)\nax.legend([\"IPCC (Apr. 2022)\", \"IGCC (Jun. 2023)\", \"CAT (Nov. 2022)\"], loc=\"lower right\")\nax.set_xlabel(\"\")\nax.set_ylabel(\"Gt CO₂-eq / yr\")\nax.set_title(\"Global Emissions (using different source datasets)\");\n\n\n\n\n\nFigure 1: Global emission estimates from IPCC AR6 WGIII SPM, IGCC (2023), and CAT (2022), each using different sources\n\n\n\n\nIt might appear surprising but there exists no complete and regularly updated global emissions dataset which covers the greenhouse gases needed to run a simple climate model or to answer the question what are global emissions levels currently at with confidence. Usually, each time a new combination of source datasets has to be assembled. Depending on approach the values might differ significantly.\nIPCC AR6 WGIII reported 59 Gt CO₂-eq in 2019, the Indicators of Global Climate Change 2022 paper (Forster et al. 2023) used some different data sources and updated landuse data and reported 55 Gt CO₂-eq. The Climate Action Tracker had 52.3 Gt CO₂-eq for 2019 in its November 2022 update.\nSome of the differences can be explained by different choice of dataset but the decision which dataset to use sometimes appear arbitrary. In the Indicators of Global Climate Change 2022 paper, an update to the data published in the IPCC’s AR6 report, the authors pick different data sources:\n\nWe also use the same type of data sources but make important changes to the specific selection of data sources to further improve the quality of the data, as suggested in the knowledge gap discussion of the WGIII report (Dhakal et al., 2022). Instead of using EDGAR data (which are now available as version 7), we use GCB data for CO2-FFI, PRIMAP-hist data for CH4 and N2O, and atmospheric concentrations with best-estimate lifetimes for UNFCCC F-gas emissions (Hodnebrog et al., 2020). As in AR6 WGIII we use GCB for net CO2-LULUCF emissions, taking the average of three bookkeeping models.\n\n(Forster et al. 2023)\nThey give the reason for their choices as follows:\n\nThere are three reasons for these specific data choices. First, national greenhouse gas emissions inventories tend to use improved, higher-tier methods for estimating emissions fluxes than global inventories such as EDGAR or CEDS (Dhakal et al., 2022; Minx et al., 2021). As GCB and PRIMAP-hist integrate the most recent national inventory submissions to the UNFCCC, selecting these databases makes best use of country-level improvements in data-gathering infrastructures.\n\n(Forster et al. 2023)\nIf the suggestion to use more data from national inventories can be inferred from the Knowledge Gaps section in the IPCC WGIII Chapter 2 discussion, why wasn’t it already used in AR6? The data sources used in the IGCC report were available then as well.\nGiven the number of datasets there are other combinations possible. A recent paper on National contributions to climate change due to historical emissions, with quite some overlap of authors with the IGCC paper, prefers third-party reported data which lie in the middle of other estimates:\n\nAs discussed above, Minx et al. (ref. 64) compared available estimates of CH4 and N2O emissions and found that PRIMAP-hist (TP scenario) lies centrally amongst those estimates. […] Hence, we note that the CH4 and N2O emissions estimates used in the current study lie centrally within a large uncertainty range globally and within a poorly constrained uncertainty range on national scales.\n\n(Jones et al. 2023)\nIn any case, more discussion and research is needed, as was discussed in the peer review of the IGCC paper.\nDifferent choices have also been made in previous IPCC reports. AR4 wrote in its chapter on “Energy, emissions and trends in Research and Development – are we on track?” that\n\n[a] variety of sources exist for determining global and regional GHG and other climate forcing agent trends. Each source has its strengths and weaknesses and uncertainties.\n\nFor its assessment it appears to have used EDGAR and CDIAC. Then, AR5 used versions of IEA and EDGAR data (Krey et al. 2014).\nIt is hard to disentangle changes over time and to understand differences between studies if different datasets are used every time. The detailed review of CO₂ datasets by Andrew (2020b) found that differences between datasets to a large part come down to different system boundaries, the inclusion or omission of sources. It also included a call for an Intercomparison Project:\n\nGiven the inconsistent system boundaries across emissions datasets, one could conceive of a “carbon emissions dataset intercomparison project”, or CEDIP, along the lines of the Coupled Model Intercomparison Project (CMIP) and other related model comparison projects. A core part of these intercomparison projects is the requirement that participants report model outputs to a specified and very clear template such that the issue of system boundary differences is removed. For example, an estimate for global total CO2 emissions could not be reported for a dataset if it excluded sources or countries. In effect, a CEDIP would extend the work done in this article, allowing each data provider to submit according to their superior understanding of their own datasets, permitting more robust comparison, and, critically, allowing lessons to be gained such that estimates can be improved.\n\nIn the reply to Reviewer #1 Robbie Andrew wrote:\n\n\nPage 40 line 637: Would a recommendation to data producers be to make their methodology and data sources more transparent to allow for better understanding?\n\nThe difficulty I have here is what concrete suggestions can be made for doing this. I know that different groups have thought a lot about how to transparently and comprehensively document methods and sources, but still we come up with a lot of missing and obscured information. I tend to think this is almost unsolvable. While it might be thought that the best approach might be to have a standard format, the methods differ quite substantially such that it’s not necessarily straightforward to report them in the same way.\n\n(emphasis mine, Andrew 2020a)\nGetting data providers to agree on a common format is definitely a challenge and releasing or cleaning up data pipelines is not a priority for researchers in the current academic system.\nAnother issue is the interdependence of datasets, which makes it hard to assess uncertainty from differences between datasets. From the same study the construction and relationships of CO₂ emissions datasets is shown below.\n\n\n\nFigure 1 from Andrew (2020b) shows interrelation and build-up of different CO₂ datasets, see original study for detailed caption (CC-BY)\n\n\n\nCommunity projects\nThere exist a number of emissions data projects who already have elements of community projects. Even open peer review and working in public can improve the process and signal openness to outside contributors.\nThe Global Carbon Budget, an annually published report which is part of the Global Carbon Project is something to look into when thinking on how to produce datasets from the community (Friedlingstein et al. 2022). While there are many co-authors collaborating only a small number is directly working on fossil and land-use emissions, as other area of the Carbon Cycle are also covered in the paper. In any case, the lack of direct funding has been a persistent problem:\n\nThe work we do in @gcarbonproject has zero direct funding, we have to align with other project activities to cover costs. Yet, we persist in updating annually.\nThese seem to be standard issues for anyone working on data.\n\n(Glen Peters on Twitter)\nThe Global Carbon Budget is widely used, but covers only CO₂. The PRIMAP-hist dataset covers all Kyoto greenhouse gases (Gütschow et al. 2016) but doesn’t include emissions from international aviation and shipping. Emissions from land-use are not included in the main file but only in a separate file and come with a caveat since “they are constructed from different sources using different methodologies and are not harmonized” (Gütschow and Pflüger 2023).\nIn a comment on the announcement post Mika Pflüger mentioned the potentially collaborative setup for doing the hard work of freeing data submitted to the UN from PDFs and the challenges with storing larger data on GitHub. Code and data can be found in their GIN server.\nThe Community Emissions Data System (CEDS) for Historical Emissions (Hoesly et al. 2018) covers a different subset of species and is probably the most open of the emission products . The code on GitHub is available and only some input data from the IEA is missing to make this fully reproducible. However, long-term sustainability has been a question as well from Reviewer #1:\n\nAn outline of long-term plans for the CEDS database is needed in the summary section to build confidence in its sustainability. Modelers would like to know if they can rely on the CEDS system working even after CMIP6. What are the plans for maintenance of the back-end software, frequency of updates to the input data and for maintaining funding for CEDS?\n\n(Anonymous 2017)\nThe MATCH (Ad-hoc group for the modelling and assessment of contributions to climate change) working group is quite interesting in this context. As part of UNFCCC negotiations Brazil proposed in 1997\n\nto set differentiated emissions reduction targets for Parties according to the impact of their historic emissions on temperature rise (document FCCC/AGBM/1997/MISC.1/Add.3).\n\nFrom the expert meetings an open group of voluntary contributors emerged, who published several papers, including assessments of historical emissions, supported by governments who funded travel and administrative support. It could be instructive to learn more from the history of this project (and how to prevent results getting lost when domains aren’t renewed anymore.)\nWhat are the challenges for having an emissions dataset intercomparison project? Have any proposals already be written? How can we get a regularly updated dataset of the inputs required to run a simple climate model? Do we need something like the Global Carbon Project for all greenhouse gases?\n\nWe have put a lot of effort into understanding the variation in fossil CO₂ emissions, but what about other GHG emissions?\nI would say we have some work to do… We need a @gcarbonproject covering all GHG emissions! https://essd.copernicus.org/articles/13/5213/2021/\n\n(Glen Peters on Twitter)\nAnd do we have to rely on crowdfunding to get it?\n\nYes please. Not having one single authoritative dataset for non-CO2 emissions makes running an emissions-based simple climate model particularly difficult🙃\nWill donate $10 to a crowdfunder?\n\n(Chris Smith on Twitter)\nLeave your thoughts and ideas in the comments!\n\n\n\n\n\nReferences\n\nAndrew, Robbie. 2020a. “Responses to Reviews.” Copernicus GmbH. https://doi.org/10.5194/essd-2020-34-ac1.\n\n\n———. 2020b. “A Comparison of Estimates of Global Carbon Dioxide Emissions from Fossil Carbon Sources.” Earth System Science Data 12 (2): 1437–65. https://doi.org/10.5194/essd-12-1437-2020.\n\n\nAnonymous. 2017. “Review of Hoesly Et Al for Publication in ACP,” April. https://doi.org/10.5194/gmd-2017-43-rc1.\n\n\nForster, Piers M., Christopher J. Smith, Tristram Walsh, William F. Lamb, Robin Lamboll, Mathias Hauser, Aurélien Ribes, et al. 2023. “Indicators of Global Climate Change 2022: Annual Update of Large-Scale Indicators of the State of the Climate System and Human Influence.” Earth System Science Data 15 (6): 2295–2327. https://doi.org/10.5194/essd-15-2295-2023.\n\n\nFriedlingstein, Pierre, Michael O’Sullivan, Matthew W. Jones, Robbie M. Andrew, Luke Gregor, Judith Hauck, Corinne Le Quéré, et al. 2022. “Global Carbon Budget 2022.” Earth System Science Data 14 (11): 4811–4900. https://doi.org/10.5194/essd-14-4811-2022.\n\n\nGütschow, Johannes, M. Louise Jeffery, Robert Gieseke, Ronja Gebel, David Stevens, Mario Krapp, and Marcia Rocha. 2016. “The PRIMAP-hist National Historical Emissions Time Series.” Earth System Science Data 8 (2): 571–603. https://doi.org/10.5194/essd-8-571-2016.\n\n\nGütschow, Johannes, and Mika Pflüger. 2023. “The PRIMAP-Hist National Historical Emissions Time Series (1750-2021) V2.4.2.” Zenodo. https://doi.org/10.5281/ZENODO.7727475.\n\n\nHoesly, Rachel M., Steven J. Smith, Leyang Feng, Zbigniew Klimont, Greet Janssens-Maenhout, Tyler Pitkanen, Jonathan J. Seibert, et al. 2018. “Historical (17502014) Anthropogenic Emissions of Reactive Gases and Aerosols from the Community Emissions Data System (CEDS).” Geoscientific Model Development 11 (1): 369–408. https://doi.org/10.5194/gmd-11-369-2018.\n\n\nJones, Matthew W., Glen P. Peters, Thomas Gasser, Robbie M. Andrew, Clemens Schwingshackl, Johannes Gütschow, Richard A. Houghton, Pierre Friedlingstein, Julia Pongratz, and Corinne Le Quéré. 2023. “National Contributions to Climate Change Due to Historical Emissions of Carbon Dioxide, Methane, and Nitrous Oxide Since 1850.” Scientific Data 10 (1). https://doi.org/10.1038/s41597-023-02041-1.\n\n\nKrey, Volker, Omar Masera, Geoffrey Blanford, Thomas Bruckner, Roger Cooke, Karen Fisher-Vanden, Helmut Haberl, et al. 2014. “Annex 2-Metrics and Methodology.”"
  },
  {
    "objectID": "posts/polyclimate-global-projections/index.html",
    "href": "posts/polyclimate-global-projections/index.html",
    "title": "Polyclimate Global Projections",
    "section": "",
    "text": "In 2015 the legally binding Paris Agreement included the overarching goals of holding\n\n“the increase in the global average temperature to well below 2 °C above pre-industrial levels and pursuing efforts to limit the temperature increase to 1.5 °C above pre-industrial levels, recognizing that this would significantly reduce the risks and impacts of climate change”.\n\nThe question of which temperature level will be reached when is thus crucial. There exist a number of projects, reports from international organizations, as well as research papers aiming to answer the question what level of global temperature rise will be reached at the end of the century or how big the gap to scenarios consistent with temperature targets is. This is done under consideration of pledges and Nationally Determined Contributions (NDCs) of countries or analyzing currently implemented or planned policies, for example:\n\nthe UNEP Emissions Gap Reporte reports,\nthe Climate Action Tracker,\nassessments published by the UNFCCC as NDC synthesis reports, or\nthe IEA.\n\nThe Remaining Carbon Budget approach is another widely used metric to track the progress, or rather non-progress, in keeping below the agreed temperature limits. It is most often reported as n years remaining until the budget is used up and often depicted as a countdown clock, by media and research institutes alike.\n\n\n\n\n\n\n\n(a) MCC Countdown Clock (Screenshot from mcc-berlin.net)\n\n\n\n\n\n\n\n(b) taz Countdown Clock (Screenshot from taz.de)\n\n\n\n\n\n\n\n(c) IGCC/Climate Change Tracker (Screenshot from climatechangetracker.org)\n\n\n\n\nFigure 1: Carbon Budget Visualizations\n\n\nWhile the Budget approach is liked by NGOs and activists as it can be used to clearly define the remaining shares of countries, cities, or sectors and is also used in legislation, for example in the UK Carbon Budgets, it has been criticized a lot. Changes in input or reference data, uncertainties in the climate response, and definitional issues have led Glen Peters to ask in Beyond carbon budgets whether the\n\n“carbon budget concept has perhaps served its purpose, time is short. To enact policy, a carbon budget is woefully too simplified.”\n\n(Peters 2018)\nFully reproducible Remaining Carbon Budgets, which are required to disentangle the differences between reported budgets, have only recently become available, see for example (Nicholls et al. 2020) and the AR6 Carbon Budget Calculations on GitHub.\nDespite efforts to improve the understanding and comparability of the Remaining Carbon Budget approach there remains confusion when updates are published. Recently, the Indicators of Global Climate Change initiative included an update of the AR6 WGI budget, which shortened the time until the budget will be used up by about two years. Some media adopted their online trackers, for example the German daily taz (Figure 1 (b)), which before used the numbers based on the IPCC report from MCC (Figure 1 (a)). The IGCC dashboard (see Figure 1 (c)) includes a slider for the likelihood to stay under 1.5 °C and makes the implied assumption of future CO₂ emissions transparent, which is another communication challenge.\nProbably not obvious to most people discussing the Carbon Budget, but mentioned in the Climate Change Tracker explanation text and in the IGCC paper is that the year of the budget being exhausted is not necessarily the year when 1.5 °C is reached.\n\n“Note that the 50 % RCB is expected to be exhausted a few years before the 1.5 °C global warming level is reached due to the way it factors future warming from non-CO2 emissions into its estimate.”\n\n(Forster et al. 2023)\nFor a deeper discussion of the Opportunities and challenges in using remaining carbon budgets to guide climate policy see also Matthews et al. (2020).\nIn contrast to the short term and rapidly shrinking Remaining Carbon Budgets are the assessments which report being on a pathway to n.m °C at the end of the century. Often a distinction is made between pathways based on implemented policies, NDC pledges, or optimistic assumptions of full implementation of all net zero targets.\nThe Climate Action Tracker is currently reporting 2.7 °C as its headline number for 2100, based on policies and actions, see Figure 2.\n\n\n\n\n\n\n\n(a) CAT Thermometer\n\n\n\n\n\n\n\n(b) CAT 2100 Warming Projections\n\n\n\n\nFigure 2: Climate Action Tracker assessment, November 2022 © 2009-2023 by Climate Analytics and NewClimate Institute\n\n\nThe 2022 UNEP Gap Report has 2.8°C with policies currently in place and the 2022 UNFCC NDC Synthesis Report summarizes:\n\n” The best estimate of peak temperature in the twenty-first century (projected mostly for 2100 when temperature continues to rise) is in the range of 2.1–2.9 °C depending on the underlying assumptions.”\n\nMost of these assessments don’t report the question when 1.5 or 2.0 °C will be reached. Underlying are a number of assumptions, especially for the extension until 2100 and its dependency on the underlying scenario databases. This makes it difficult to compare different assessments, for a detailed discussion see for example Jeffery et al. (2018) and Gütschow et al. (2018). An overview of recent studies can be found in this 2022 briefing paper from Climate Resource.\nThe public discourse is thus dominated by either a rapidly being used up budget (sometimes communicated with a faux accuracy of hundredths of seconds) or by a being on a rather deterministic sounding pathway to a temperature in 2100, when, using average global life expectancy, everybody currently alive and their children won’t be around anymore.\nI think that a different approach could amend these perspectives and be less reliant on scenario databases and their sometimes opaque assumptions on technologies or negative emissions. One could construct stylized scenarios, constant emissions, reductions or further increase in emissions and run these in the same way as scenarios based on NDCs or policies. The results could then be reported as follows:\nIf we reduce emissions by n% per year, 1.5 °C will be reached between 20xx and 20yy.\nIf emissions plateau for n years, we will reach a level of 1.5 °C in x years.\nIf emissions keep rising at n% per year, the 2.0 °C limit will be breached between 20xx and 20yy.\nAggregated NDCs could also be included, for example first follow an NDC trajectory and then decline or plateau.\nAs a proof of concept I used the excellent climate-assessment package, used in the IPCC WG3 scenario assessment (Kikstra et al. 2022). For testing the approach I constructed three basic scenarios with the main greenhouse gases. Starting from the historical emissions used in the climate-assessment package I extended them with the change rates as reported in the IGCC emissions update (Forster et al. 2023). Next to a ‘persistence’ scenario with constant emissions, a continuous 5% reduction and 1% increase were considered as illustrative examples. Remaining greenhouse gases beyond CO₂, CH₄, N₂O, and other inputs and disaggregation of F-gases were infilled using Silicone as included in the climate-assessment workflow.\nFigure 3 shows the stylized scenarios and their temperature response for the median and 33rd to 66th percentile range using the FaIR climate model.\n\n\n\n\n\n\n\n(a) Stylized scenario with 5% reductions\n\n\n\n\n\n\n\n\n\n(b) Stylized scenario with constant emissions\n\n\n\n\n\n\n\n\n\n(c) Stylized scenario with 1% increase\n\n\n\n\nFigure 3: Examples of stylized scenarios and their temperature response.\n\n\nThis is of course only illustrative, many aspects need further thought and exploration:\n\n2022 (or soon 2023) emissions could also be used as a starting point,\ninstead of percent reductions, one could use a more complex function to account for “hard-to-abate” and negative emissions (see discussion on Robbie Andrew’s figure of the mitigation challenge) or a simple linear pathway\none could use specific lower bounds and reduction rates for different species\nall climate models available in climate-assessment or OpenSCM should be used\nthe question of updates of historical emissions and (re-)calibration\n\nIn general such a framework can also be used to analyze trade-offs between reduction rates for different species, like CO₂, CH₄, or F-Gases.\nIn the example above I used the automatic infilling which is also something that needs further research. For the highly stylized scenarios it could make sense to extend all inputs in the same way or to use some other relationship from the literature or modelling. See Figure 4 for some examples of infilled inputs.\n\n\n\n\n\n\n\n(a) Infilled sulfur emissions\n\n\n\n\n\n\n\n(b) Infilled SF6 emissions\n\n\n\n\nFigure 4: Infilled inputs for the stylized scenarios above.\n\n\nIn any case, making such an assessment requires the collaboration and inputs from many researchers, a number of tools and datesets. This makes it perfect to become project Polyclimate1. I believe it could provide a useful addition to existing global projections and potentially be communicated more easily. A repository with the proof-of-concept notebooks used for creating and running the scenarios is available on GitHub.\nLeave your thought and comments below!\n\n\n\n\nReferences\n\nForster, Piers M., Christopher J. Smith, Tristram Walsh, William F. Lamb, Robin Lamboll, Mathias Hauser, Aurélien Ribes, et al. 2023. “Indicators of Global Climate Change 2022: Annual Update of Large-Scale Indicators of the State of the Climate System and Human Influence.” Earth System Science Data 15 (6): 2295–2327. https://doi.org/10.5194/essd-15-2295-2023.\n\n\nGütschow, Johannes, Mairi Louise Jeffery, Michiel Schaeffer, and Bill Hare. 2018. “Extending Near-Term Emissions Scenarios to Assess Warming Implications of Paris Agreement NDCs.” Earth’s Future 6 (9): 1242–59. https://doi.org/10.1002/2017EF000781.\n\n\nJeffery, M. Louise, Johannes Gütschow, Marcia R. Rocha, and Robert Gieseke. 2018. “Measuring Success: Improving Assessments of Aggregate Greenhouse Gas Emissions Reduction Goals.” Earth’s Future 6 (9): 1260–74. https://doi.org/10.1029/2018EF000865.\n\n\nKikstra, Jarmo S., Zebedee R. J. Nicholls, Christopher J. Smith, Jared Lewis, Robin D. Lamboll, Edward Byers, Marit Sandstad, et al. 2022. “The IPCC Sixth Assessment Report WGIII Climate Assessment of Mitigation Pathways: From Emissions to Global Temperatures.” Geoscientific Model Development 15 (24): 9075–9109. https://doi.org/10.5194/gmd-15-9075-2022.\n\n\nMatthews, H. Damon, Katarzyna B. Tokarska, Zebedee R. J. Nicholls, Joeri Rogelj, Josep G. Canadell, Pierre Friedlingstein, Thomas L. Frölicher, et al. 2020. “Opportunities and Challenges in Using Remaining Carbon Budgets to Guide Climate Policy.” Nature Geoscience 13 (12, 12): 769–79. https://doi.org/10.1038/s41561-020-00663-3.\n\n\nNicholls, Z. R. J., R. Gieseke, J. Lewis, A. Nauels, and M. Meinshausen. 2020. “Implications of Non-Linearities Between Cumulative CO2 Emissions and CO2-induced Warming for Assessing the Remaining Carbon Budget.” Environmental Research Letters 15 (7): 074017. https://doi.org/10.1088/1748-9326/ab83af.\n\n\nPeters, Glen P. 2018. “Beyond Carbon Budgets.” Nature Geoscience 11 (6, 6): 378–80. https://doi.org/10.1038/s41561-018-0142-4."
  }
]